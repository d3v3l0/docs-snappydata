---
title: Using SnappyData Service for PCF
owner: Partners
---

<strong><%= modified_date %></strong>

This topic describes how to create and bind a service instance of SnappyData, interact with a SnappyData cluster on Kubernetes, connect to SnappyData cluster using JDBC driver and how to submit SnappyData jobs. 

##<a id='createserinst'></a> Create and Bind a Service Instance Using the cf CLI

To create a SnappyData service instance using the cf CLI, perform the following steps:

1.	Set your API endpoint to the Cloud Controller of your deployment.

		$ cf api api.YOUR-SYSTEM-DOMAIN
		Setting api endpoint to api.YOUR-SYSTEM-DOMAIN...
		OK
		API endpoint:  https://api.YOUR-SYSTEM-DOMAIN (API version: 2.59.0)
		Not logged in. Use 'cf login' to log in.
		
2.	Log in to your deployment and select an org and a space.

		$ cf login
		API endpoint: https://api.YOUR-SYSTEM-DOMAIN
		Email> user@example.com
		Password>

3.	List the services and locate the SnappyData service.

		$ cf marketplace
		Getting services from marketplace in org system / space apps-manager as admin...
		OK


		service          plans                       description
		SnappyData       snappy_plan1, ...           Service Broker implementation for SnappyData database


		TIP:  Use 'cf marketplace -s SERVICE' to view descriptions of individual plans of a given service.

4.	Create an instance of the SnappyData service, specifying both the name of the service plan and the name of the service instance.

		$ cf create-service SnappyData YOUR-SERVICE-PLAN SNAPPY-Instance

    This command launches the SnappyData cluster in your Kubernetes environment. 

5.	Bind the instance to your application.

		$ cf bind-service snappy-app SNAPPY-Instance
		Binding service SNAPPY-Instance to app snappy-app in org example / space development as user@example.com...
		OK
		TIP: Use 'cf restage snappy-app' to ensure your env variable changes take effect

6.	Finally, restart the app so that the access details of the service are available to it via the environment variable **VCAP_SERVICES**.

		$ cf restage snappy-app
        
        OR

        $ cf restart snappy-app

    The details include locator hostname and port, lead hostname, and jobserver port among other parameters.

##<a id='interacting'></a> Interact with SnappyData Cluster on Kubernetes

SnappyData Helm chart creates services that allows you to make JDBC connections, execute Spark jobs, and access
SnappyData Pulse etc.  
Services of the type LoadBalancer have external IP address assigned and can be used to connect from outside of Kubernetes cluster.
<a id= output> </a>To check the service created for SnappyData deployment, use command `kubectl get svc --namespace=snappy`. The following output is displayed:


```
NAME                        TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                                        AGE
snappydata-leader           ClusterIP      None            <none>           5050/TCP                                       5m
snappydata-leader-public    LoadBalancer   10.51.255.175   35.232.102.51    5050:31964/TCP,8090:32700/TCP,3768:32575/TCP   5m
snappydata-locator          ClusterIP      None            <none>           10334/TCP,1527/TCP                             5m
snappydata-locator-public   LoadBalancer   10.51.241.224   104.198.47.162   1527:31957/TCP                                 5m
snappydata-server           ClusterIP      None            <none>           1527/TCP                                       5m
snappydata-server-public    LoadBalancer   10.51.248.27    35.232.16.4      1527:31853/TCP                                 5m

```
In the above output, three services namely **snappydata-leader-public**, **snappydata-locator-public** and **snappydata-server-public** of type **LoadBalancer** are created. These services have external IP addresses assigned and therefore can be accessed from outside Kubernetes. The remaining services that do not have external IP addresses are those that are created for internal use.
 
+   **snappydata-leader-public** service exposes port **5050** for SnappyData Pulse and port **8090** to accept SnappyData jobs.
+   **snappydata-locator-public** service exposes port **1527** to accept JDBC connections.


You can do the following on the SnappyData cluster that is deployed on Kubernetes:

- [Connect SnappyData using JDBC Driver](#jdbckubernetes)

- [Submit SnappyData Jobs](#jobkubernetes)

##<a id='jdbckubernetes'></a> Connect using JDBC Driver

For Kubernetes deployments, JDBC clients can connect to SnappyData cluster using the JDBC URL that is derived from the **snappydata-locator-public** service.

**To connect to SnappyData using JDBC driver in Kubernetes:**

1.	Check the SnappyData services running in Kubernetes cluster.</br>
`kubectl get svc --namespace=snappy`</br>
The output displays the external IP address  of the *snappydata-locator-public* service and the port number for external connections as follows:

        ```
        NAME                        TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                                        AGE
        snappydata-leader           ClusterIP      None            <none>           5050/TCP                                       5m
        snappydata-leader-public    LoadBalancer   10.51.255.175   35.232.102.51    5050:31964/TCP,8090:32700/TCP,3768:32575/TCP   5m
        snappydata-locator          ClusterIP      None            <none>           10334/TCP,1527/TCP                             5m
        snappydata-locator-public   LoadBalancer   10.51.241.224   104.198.47.162   1527:31957/TCP                                 5m
        snappydata-server           ClusterIP      None            <none>           1527/TCP                                       5m
        snappydata-server-public    LoadBalancer   10.51.248.27    35.232.16.4      1527:31853/TCP                                 5m

        ```
2.	Use the external IP address and port of the **snappydata-locator-public** services to connect to SnappyData cluster using JDBC connections. For example, based on the above output, the JDBC URL to be used will be [jdbc:snappydata://104.198.47.162:1527/]()

You can refer to [SnappyData documentation](http://snappydatainc.github.io/snappydata/howto/connect_using_jdbc_driver/) for an example of JDBC program and for instructions on how to obtain JDBC driver using Maven/SBT co-ordinates.


##<a id='jobkubernetes'></a> Submit SnappyData Jobs

Refer to the [How Tos section](http://snappydatainc.github.io/snappydata/howto/run_spark_job_inside_cluster/) in SnappyData documentation to understand how to submit SnappyData jobs.
However, for submitting a SnappyData job in Kubernetes deployment, you need to use the **snappydata-leader-public** service that exposes port **8090** to run the jobs.

**To submit a SnappyData job in Kubernetes deployment:**

1.	Check the SnappyData services running in Kubernetes cluster.</br>`kubectl get svc --namespace=snappy`</br>

        ```
        # check the SnappyData services running in K8S cluster
        kubectl get svc --namespace=snappy
        # This will show output like following

        NAME                        TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                                        AGE
        snappydata-leader           ClusterIP      None            <none>           5050/TCP                                       5m
        snappydata-leader-public    LoadBalancer   10.51.255.175   35.232.102.51    5050:31964/TCP,8090:32700/TCP,3768:32575/TCP   5m
        snappydata-locator          ClusterIP      None            <none>           10334/TCP,1527/TCP                             5m
        snappydata-locator-public   LoadBalancer   10.51.241.224   104.198.47.162   1527:31957/TCP                                 5m
        snappydata-server           ClusterIP      None            <none>           1527/TCP                                       5m
        snappydata-server-public    LoadBalancer   10.51.248.27    35.232.16.4      1527:31853/TCP                                 5m
        ```

    The output displays the external IP address of **snappydata-leader-public** service which must be noted. 
3.	Change to SnappyData product directory.</br>`cd $SNAPPY_HOME`</br>

3.	Submit the job using the external IP of the **snappydata-leader-public** service and the port number **8090** in the **--lead** option.</br> Following is an example of submitting a SnappyData Job:

        ```
        bin/snappy-job.sh submit
        --app-name CreatePartitionedRowTable
          --class org.apache.spark.examples.snappydata.CreatePartitionedRowTable
          --app-jar examples/jars/quickstart.jar
          --lead 35.232.102.51:8090
        ```
       

